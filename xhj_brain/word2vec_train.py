import jieba
from gensim import corpora
from gensim import models

def v2v_train(lst):
    ch_lst = lst
    cut_words = map(lambda s: list(jieba.cut(s)), ch_lst)
    word_list = list(cut_words)
    #####################################################################
    # 赋给语料库中每个词(不重复的词)一个整数id
    dictionary = corpora.Dictionary(word_list)
    dictionary.save('./data/all_ch_dict.dict')
    print('---> all_ch_dict.dict (generated by word2vec_train.py) <--- saving succeeded.')
    #dictionary = corpora.Dictionary.load('all_ch_dict.dict')
    new_corpus = [dictionary.doc2bow(text) for text in word_list]
    # 元组中第一个元素是词语在词典中对应的id，第二个元素是词语在文档中出现的次数
    #print(new_corpus)
    # 语料库中每个词对应的id
    #print(dictionary.token2id)
    ###################################
    tfidf = models.TfidfModel(new_corpus)
    tfidf.save("./data/ch_all_model.tfidf")
    print('---> ch_all_model.tfidf (generated by word2vec_train.py) <--- saving succeeded.')
    print('1.  ------------->  word2vec_train down !')

def ordinal():
    file = './data/train_data_header_test.csv'
    # df = pd.read_csv(file, encoding='gbk')
    #
    # x = '男'
    # df['Sex'].fillna(x, inplace=True)
    # lst = []
    # for i in df['Sex'].tolist():
    #     lst.append([i])
    # enc = preprocessing.OrdinalEncoder().fit(lst)
    #
    # y = enc.transform(lst)
    # print(y)

if __name__ == "__main__":
    v2v_train()



